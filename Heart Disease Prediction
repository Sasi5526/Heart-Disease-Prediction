# -*- coding: utf-8 -*-
"""
Created on Thu May 14 19:31:05 2020

@author: sasim
"""

import pandas as pd
import matplotlib.pyplot as plt
import math
import numpy as np
import seaborn as sb
import plotly.express as px

dataset = pd.read_csv("D:\\sasi\\study\\ML\\ML project\\heart-disease-prediction-using-logistic-regression\\framingham.csv")

dataset.head()
dataset.info()

# checking distributions using histograms
fig = plt.figure(figsize = (15,20))
ax = fig.gca()
dataset.hist(ax = ax)

# checking which features are correlated with each other and are correlated with the outcome variable
 
#Ploting the relation between gender who have more risk towards Heart disease
plt.figure(figsize=(12,8))
sb.barplot(x=dataset["sex"], y=dataset["TenYearCHD"])
plt.title("Graph showing which gender has more risk of coronary heart disease CHD")
plt.xlabel("0 is female and 1 is male",size=20)
plt.ylabel("total cases", size=20)
plt.xticks(size=12)
plt.yticks(size=12)
#Males have Heavy risk than Females

#Plotting a linegraph to check the relationship between age and cigsPerDay, totChol, glucose.
cig_g = dataset.groupby("age").cigsPerDay.mean()
tot_g = dataset.groupby("age").totChol.mean()
glu_g = dataset.groupby("age").glucose.mean()

plt.figure(figsize=(12,8))
sb.lineplot(data= cig_g, label="cigsPerDay")
sb.lineplot(data= tot_g, label="totChol")
sb.lineplot(data= glu_g, label="glucose")
plt.title("Graph showing totChol and cigsPerDay in every age group.")
plt.xlabel("age", size=20)
plt.ylabel("count", size=20)
plt.xticks(size=12)
plt.yticks(size=12)


# which Age group are more smokers
Smoker = dataset.groupby("age",as_index=False).currentSmoker.sum()

plt.figure(figsize=(12,8))
sb.barplot(x=Smoker["age"], y=Smoker["currentSmoker"])
plt.title("Graph showing which age group has more smokers.")
plt.xlabel("age", size=20)
plt.ylabel("currentSmokers", size=20)
plt.xticks(size=12)
plt.yticks(size=12)
# the people at age 40 are heavy Smokers

#the Risk of Smokers who smoke cigar per day towards heart disease
cig_per = dataset.groupby("TenYearCHD", as_index=False).cigsPerDay.mean()

plt.figure(figsize=(12,8))
sb.barplot(x=cig_per["TenYearCHD"], y=cig_per["cigsPerDay"])
plt.title("Graph showing the relation between cigsPerDay and risk of coronary heart disease.")
plt.xlabel("Rick of CHD", size=20)
plt.ylabel("cigsPerDay", size=20)
plt.xticks(size=12)
plt.yticks(size=12)

###Data Preprocesiing
dataset = dataset.rename({'male': 'sex'}, axis=1)
dataset=dataset.drop("education",axis=1)
dataset.cigsPerDay=dataset["cigsPerDay"].fillna(dataset["cigsPerDay"].mean())
dataset.BPMeds=dataset["BPMeds"].fillna(dataset["BPMeds"].mean())
dataset.totChol=dataset["totChol"].fillna(dataset["totChol"].mean())
dataset.totChol=dataset["totChol"].fillna(dataset["totChol"].mean())
dataset.BMI=dataset["BMI"].fillna(dataset["BMI"].mean())
dataset.heartRate=dataset["heartRate"].fillna(dataset["heartRate"].mean())
dataset.glucose=dataset["glucose"].fillna(dataset["glucose"].mean())

dataset.info()

###x & y
x= dataset.iloc[:,:-1]
y=dataset.iloc[:,-1]

import statsmodels.api as sm

x_copy = x
reg_OLS = sm.OLS(y,x_copy).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x=x.drop(["totChol"],axis=1)

#iteration 1
x_copy = x
reg_OLS = sm.OLS(y,x_copy).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x=x.drop(["currentSmoker"],axis=1)

#iteration 2
x_copy = x
reg_OLS = sm.OLS(y,x_copy).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

x=x.drop(["glucose"],axis=1)

#iteration 3
x_copy = x
reg_OLS = sm.OLS(y,x_copy).fit()
reg_OLS.summary()
max(reg_OLS.pvalues)

reg_OLS.rsquared
reg_OLS.rsquared_adj



# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)



# Fitting Logistic Regression to the Training set
from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(penalty='l2',C = 1.0,random_state = 0,
                                solver='sag', multi_class='ovr')
classifier.fit(x_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(x_test)
classifier.predict_proba(x_test)
classifier.predict_log_proba(x_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix, accuracy_score
confusion_matrix(y_test, y_pred)
A1=accuracy_score(y_test, y_pred)



###knearest neighbor
from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors=5,
                        metric='minkowski', p=2)

classifier.fit(x_train, y_train)

y_pred = classifier.predict(x_test)

from sklearn.metrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test, y_pred)
A2=accuracy_score(y_test, y_pred)


###naive bayes

from sklearn.naive_bayes import GaussianNB
classifier=GaussianNB()

classifier.fit(x_train, y_train)

y_pred = classifier.predict(x_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
A3=accuracy_score(y_test, y_pred)



####Decision Tree
from sklearn.tree import DecisionTreeClassifier
classifier= DecisionTreeClassifier(criterion='entropy')

classifier.fit(x_train, y_train)

y_pred = classifier.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score
confusion_matrix(y_test, y_pred)
A4=accuracy_score(y_test, y_pred)



#####mean of accuracy
import numpy as np
accuracy=np.mean([A1,A2,A3,A4])




###Random Forest
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor

classifier = RandomForestClassifier(n_estimators=10,
                                    criterion='entropy')

classifier.fit(x_train,y_train)

y_pred = classifier.predict(x_test)


from sklearn.metrics import confusion_matrix, accuracy_score
confusion_matrix(y_test, y_pred)
accuracy_score(y_test, y_pred)

###Hyperparameter Tuning
#GridSearchCV
from sklearn.model_selection import GridSearchCV

parameter=[{'n_estimators':[10,50,100,500,1000],
            'criterion':['gini','entropy'],
            'bootstrap':[True,False],
            'max_depth':[2,3,4,5,6]}]

grid_search=GridSearchCV(classifier,
                         param_grid=parameter,
                         scoring='accuracy',
                         cv=10)

grid_search.fit(x_train,y_train)

grid_search.best_score_
grid_search.best_params_
 
classifier=RandomForestClassifier(bootstrap=True,
                                  criterion='gini',
                                  max_depth=6,
                                  n_estimators=10)

classifier.fit(x_train,y_train)
y_pred=classifier.predict(x_test)
from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)





